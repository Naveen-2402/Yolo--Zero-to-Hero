{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ab8ea-4a1c-4666-a204-8040617deee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Loop through all files in the current directory\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith('.pickle'):\n",
    "        # Load the pickle file\n",
    "        with open(filename, 'rb') as pickle_file:\n",
    "            data = pickle.load(pickle_file)\n",
    "        # Create a corresponding text file name\n",
    "        text_filename = filename.replace('.pickle', '.txt')\n",
    "\n",
    "        # Write the contents to the text file\n",
    "        with open(text_filename, 'w') as text_file:\n",
    "            text_file.write(str(data))\n",
    "\n",
    "        print(f'Converted {filename} to {text_filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311edce-c558-4325-a69b-bcb8f2158195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the output directory\n",
    "output_folder = './Yolo Annotations'\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# List of keypoints in the required order\n",
    "keypoints_order = [\n",
    "    \"nose\", \"upper_jaw\", \"lower_jaw\", \"mouth_end_right\", \"mouth_end_left\",\n",
    "    \"right_eye\", \"right_earbase\", \"right_earend\", \"right_antler_base\", \"right_antler_end\",\n",
    "    \"left_eye\", \"left_earbase\", \"left_earend\", \"left_antler_base\", \"left_antler_end\",\n",
    "    \"neck_base\", \"neck_end\", \"throat_base\", \"throat_end\", \"back_base\",\n",
    "    \"back_end\", \"back_middle\", \"tail_base\", \"tail_end\", \"front_left_thai\",\n",
    "    \"front_left_knee\", \"front_left_paw\", \"front_right_thai\", \"front_right_knee\",\n",
    "    \"front_right_paw\", \"back_left_knee\", \"back_left_paw\", \"back_left_thai\",\n",
    "    \"back_right_thai\", \"back_right_paw\", \"back_right_knee\", \"belly_bottom\",\n",
    "    \"body_middle_right\", \"body_middle_left\"\n",
    "]\n",
    "\n",
    "# Function to process each input annotation file and convert to YOLO format\n",
    "def process_annotation_file(input_file, output_file):\n",
    "    try:\n",
    "        # Read the content of the input annotation file\n",
    "        with open(input_file, 'r') as f:\n",
    "            data = eval(f.read().strip())  # Read and convert the data to a dictionary\n",
    "\n",
    "        if 'a1' not in data:\n",
    "            print(f\"Skipping {input_file}: Missing 'a1' data\")\n",
    "            return\n",
    "        \n",
    "        annotation = data['a1']\n",
    "        \n",
    "        # Extract bounding box\n",
    "        bbox = annotation.get('bbox')\n",
    "        if bbox:\n",
    "            xtl, ytl, w, h = bbox\n",
    "            # Assuming width and height (could be extracted if included in your text files)\n",
    "            width = 1024  # Default width if not specified\n",
    "            height = 768  # Default height if not specified\n",
    "\n",
    "            # Normalize the bounding box\n",
    "            cx = (xtl + w / 2) / width\n",
    "            cy = (ytl + h / 2) / height\n",
    "            norm_w = w / width\n",
    "            norm_h = h / height\n",
    "            normalized_bbox = [cx, cy, norm_w, norm_h]\n",
    "        else:\n",
    "            print(f\"Skipping {input_file}: Missing bbox data\")\n",
    "            return\n",
    "\n",
    "        # Extract keypoints and arrange them in the required order\n",
    "        normalized_keypoints = []\n",
    "        for key in keypoints_order:\n",
    "            if key in annotation and isinstance(annotation[key], list) and len(annotation[key]) == 2:\n",
    "                x, y = annotation[key]\n",
    "                if x != -1 and y != -1:\n",
    "                    norm_x = x / width\n",
    "                    norm_y = y / height\n",
    "                    v = 2  # Visible\n",
    "                else:\n",
    "                    norm_x = norm_y = 0\n",
    "                    v = 0  # Not visible\n",
    "            else:\n",
    "                norm_x = norm_y = 0\n",
    "                v = 0  # Not visible\n",
    "\n",
    "            normalized_keypoints.append(f\"{norm_x} {norm_y} {v}\")\n",
    "\n",
    "        # Create the YOLO formatted file and save\n",
    "        with open(output_file, 'w') as tf:\n",
    "            # Write class name (0 for pose detection class)\n",
    "            tf.write(f\"0 \")\n",
    "            \n",
    "            # Write bounding box\n",
    "            tf.write(f\"{' '.join(map(str, normalized_bbox))}\")\n",
    "            tf.write(f\" \")\n",
    "            \n",
    "            # Write keypoints\n",
    "            tf.write(' '.join(normalized_keypoints))\n",
    "\n",
    "        print(f\"Processed and saved {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {input_file}: {e}\")\n",
    "\n",
    "# Process all files in the current directory\n",
    "def process_all_files():\n",
    "    for filename in os.listdir('.'):\n",
    "        if filename.endswith('.txt'):  # Assuming the input files are in TXT format\n",
    "            input_file = os.path.join('.', filename)\n",
    "            output_file = os.path.join(output_folder, os.path.splitext(filename)[0] + \"_yolo.txt\")\n",
    "            process_annotation_file(input_file, output_file)\n",
    "\n",
    "# Run the processing\n",
    "process_all_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6a17d-9836-4628-96ee-b453fdde6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List of keypoints in the required order\n",
    "keypoints_order = [\n",
    "    \"nose\", \"upper_jaw\", \"lower_jaw\", \"mouth_end_right\", \"mouth_end_left\",\n",
    "    \"right_eye\", \"right_earbase\", \"right_earend\", \"right_antler_base\", \"right_antler_end\",\n",
    "    \"left_eye\", \"left_earbase\", \"left_earend\", \"left_antler_base\", \"left_antler_end\",\n",
    "    \"neck_base\", \"neck_end\", \"throat_base\", \"throat_end\", \"back_base\",\n",
    "    \"back_end\", \"back_middle\", \"tail_base\", \"tail_end\", \"front_left_thai\",\n",
    "    \"front_left_knee\", \"front_left_paw\", \"front_right_thai\", \"front_right_knee\",\n",
    "    \"front_right_paw\", \"back_left_knee\", \"back_left_paw\", \"back_left_thai\",\n",
    "    \"back_right_thai\", \"back_right_paw\", \"back_right_knee\", \"belly_bottom\",\n",
    "    \"body_middle_right\", \"body_middle_left\"\n",
    "]\n",
    "\n",
    "# Function to process each input annotation file and convert to YOLO format\n",
    "def process_annotation_file(input_file, output_file):\n",
    "    try:\n",
    "        # Read the content of the input annotation file\n",
    "        with open(input_file, 'r') as f:\n",
    "            data = eval(f.read().strip())  # Read and convert the data to a dictionary\n",
    "\n",
    "        if 'a1' not in data:\n",
    "            print(f\"Skipping {input_file}: Missing 'a1' data\")\n",
    "            return\n",
    "        \n",
    "        annotation = data['a1']\n",
    "        \n",
    "        # Extract bounding box\n",
    "        bbox = annotation.get('bbox')\n",
    "        if bbox:\n",
    "            xtl, ytl, w, h = bbox\n",
    "            # Assuming width and height (could be extracted if included in your text files)\n",
    "            width = 1024  # Default width if not specified\n",
    "            height = 768  # Default height if not specified\n",
    "\n",
    "            # Normalize the bounding box\n",
    "            cx = (xtl + w / 2) / width\n",
    "            cy = (ytl + h / 2) / height\n",
    "            norm_w = w / width\n",
    "            norm_h = h / height\n",
    "            normalized_bbox = [cx, cy, norm_w, norm_h]\n",
    "        else:\n",
    "            print(f\"Skipping {input_file}: Missing bbox data\")\n",
    "            return\n",
    "\n",
    "        # Extract keypoints and arrange them in the required order\n",
    "        normalized_keypoints = []\n",
    "        for key in keypoints_order:\n",
    "            if key in annotation and isinstance(annotation[key], list) and len(annotation[key]) == 2:\n",
    "                x, y = annotation[key]\n",
    "                if x != -1 and y != -1:\n",
    "                    norm_x = x / width\n",
    "                    norm_y = y / height\n",
    "                    v = 2  # Visible\n",
    "                else:\n",
    "                    norm_x = norm_y = 0\n",
    "                    v = 0  # Not visible\n",
    "            else:\n",
    "                norm_x = norm_y = 0\n",
    "                v = 0  # Not visible\n",
    "\n",
    "            normalized_keypoints.append(f\"{norm_x} {norm_y} {v}\")\n",
    "\n",
    "        # Create the YOLO formatted file and save\n",
    "        with open(output_file, 'w') as tf:\n",
    "            # Write class name (0 for pose detection class)\n",
    "            tf.write(f\"0 \")\n",
    "            \n",
    "            # Write bounding box\n",
    "            tf.write(f\"{' '.join(map(str, normalized_bbox))}\")\n",
    "            tf.write(f\" \")\n",
    "            \n",
    "            # Write keypoints\n",
    "            tf.write(' '.join(normalized_keypoints))\n",
    "\n",
    "        print(f\"Processed and saved {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {input_file}: {e}\")\n",
    "\n",
    "# Process all files in the current directory\n",
    "def process_all_files():\n",
    "    for filename in os.listdir('.'):\n",
    "        if filename.endswith('.txt'):  # Assuming the input files are in TXT format\n",
    "            input_file = os.path.join('.', filename)\n",
    "            output_file = os.path.splitext(filename)[0] + \".txt\"\n",
    "            process_annotation_file(input_file, output_file)\n",
    "\n",
    "# Run the processing\n",
    "process_all_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc8404-2e00-4b24-8827-d36412d96ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
